{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZqQAR-vV2gT0",
    "outputId": "a4cc97a2-4116-4d1d-aca9-b32744bd15ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
      "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-krvjs5zq\n",
      "  Running command git clone -q https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-krvjs5zq\n",
      "Building wheels for collected packages: NVCCPlugin\n",
      "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4306 sha256=6edb6e3f480725491cb1ae6ee6768d485eed44cfe6c62e2c65c693381180b14f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-c_1b02ry/wheels/ca/33/8d/3c86eb85e97d2b6169d95c6e8f2c297fdec60db6e84cb56f5e\n",
      "Successfully built NVCCPlugin\n",
      "Installing collected packages: NVCCPlugin\n",
      "Successfully installed NVCCPlugin-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPOA-m_d2jkB",
    "outputId": "19fe65c0-c5fa-4fe5-ccb2-24407ba5ab43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created output directory at /content/src\n",
      "Out bin /content/result.out\n"
     ]
    }
   ],
   "source": [
    "%load_ext nvcc_plugin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yq257ERa1uCM",
    "outputId": "8d3d69e7-d4ac-4809-d526-c0a8b7432562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%writefile 1.cu\n",
    "%%cu\n",
    "#include <iostream>\n",
    "int main() {\n",
    "    std::cout << \"Hello world\\n\";\n",
    "    return 0;\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5q1xWlKh1v-a",
    "outputId": "382ce144-c95f-4b3f-aa80-f94bfd041cf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max error: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cu\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "\n",
    "// function to add the elements of two arrays\n",
    "__global__ void add(int n, float *x, float *y)\n",
    "{\n",
    "  for (int i = 0; i < n; i++)\n",
    "      y[i] = x[i] + y[i];\n",
    "}\n",
    "\n",
    "int main(void)\n",
    "{\n",
    " \n",
    "  int N = 1<<20; // 1M elements\n",
    "\n",
    " float *x, *y;\n",
    "\n",
    "\n",
    " cudaMallocManaged(&x, N*sizeof(float));\n",
    " cudaMallocManaged(&y, N*sizeof(float));\n",
    "\n",
    "\n",
    "  // initialize x and y arrays on the host\n",
    "  for (int i = 0; i < N; i++) {\n",
    "    x[i] = 1.0f;\n",
    "    y[i] = 2.0f;\n",
    "  }\n",
    " \n",
    "\n",
    "// Run kernel on 1M elements on the CPU\n",
    "  add<<<1,1>>>(N, x, y);\n",
    " \n",
    "\n",
    "\n",
    " cudaDeviceSynchronize();\n",
    "\n",
    "  // Check for errors (all values should be 3.0f)\n",
    "  float maxError = 0.0f;\n",
    "  for (int i = 0; i < N; i++)\n",
    "    maxError = fmax(maxError, fabs(y[i]-3.0f));\n",
    "  std::cout << \"Max error: \" << maxError << std::endl;\n",
    " \n",
    "\n",
    "  // Free memory\n",
    "  //delete [] x;\n",
    "  //delete [] y;\n",
    " \n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SgaZdPjQ3NeQ",
    "outputId": "716b51e2-9ee1-4a00-b886-62f139c7f826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing simple.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile simple.cu\n",
    "//  onehiddenlayerperceptron.cu\n",
    "//  onehiddenlayerperceptron\n",
    "\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "__global__ void kMartixByMatrixElementwise(const int nThreads, const float *m1, const float *m2, float *output) {\n",
    "    /*  Computes the product of two arrays (elementwise multiplication).\n",
    "     Inputs:\n",
    "     m1: array\n",
    "     m2: array\n",
    "     output: array,the results of the multiplication are to be stored here\n",
    "    */\n",
    "\tfor (int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\t\t i < nThreads;\n",
    "\t\t i += blockDim.x * gridDim.x)\n",
    "\t  {\n",
    "\t\toutput[i] = m1[i] * m2[i];\n",
    "\t  }\n",
    "}\n",
    "\n",
    "__device__ float* dMartixByMatrixElementwise(const float *m1, const float *m2, float *output, const int width, const int height){\n",
    "\n",
    "\tkMartixByMatrixElementwise <<< width, height >>> ( width * height, m1, m2, output );\n",
    "    cudaDeviceSynchronize();\n",
    "    return output;\n",
    "}\n",
    "\n",
    "__global__ void kMartixSubstractMatrix(const int nThreads, const float *m1, const float *m2, float *output) {\n",
    "    /*  Computes the (elementwise) difference between two arrays\n",
    "     Inputs:\n",
    "     m1: array\n",
    "     m2: array\n",
    "     output: array,the results of the computation are to be stored here\n",
    "     */\n",
    "\n",
    "\tfor (int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\t\t i < nThreads;\n",
    "\t\t i += blockDim.x * gridDim.x)\n",
    "\t  {\n",
    "\t\toutput[i] = m1[i] - m2[i];\n",
    "\t  }\n",
    "}\n",
    "\n",
    "__device__ float* dMartixSubstractMatrix(const float *m1, const float *m2, float *output, const int width, const int height){\n",
    "\n",
    "\tkMartixSubstractMatrix <<< width, height >>> ( width * height, m1, m2, output );\n",
    "    cudaDeviceSynchronize();\n",
    "    return output;\n",
    "}\n",
    "\n",
    "__global__ void kSigmoid(const int nThreads, float const *input, float *output){\n",
    "    /*  Computes the value of the sigmoid function f(x) = 1/(1 + e^-x).\n",
    "     Inputs:\n",
    "     input: array\n",
    "     output: array, the results of the computation are to be stored here\n",
    "    */\n",
    "\n",
    "\tfor (int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\t\t i < nThreads;\n",
    "\t\t i += blockDim.x * gridDim.x)\n",
    "\t  {\n",
    "\t\toutput[i] = 1.0 / (1.0 + std::exp(-input[i]));\n",
    "\t  }\n",
    "}\n",
    "\n",
    "__device__ void dSigmoid(float const *input, float *output, const int height, const int width){\n",
    "\n",
    "\tkSigmoid <<< height, width >>> (height * width, input, output);\n",
    "\tcudaDeviceSynchronize();\n",
    "}\n",
    "\n",
    "__global__ void kSigmoid_d(const int nThreads, float const *input, float *output) {\n",
    "\t/*  Computes the value of the sigmoid function derivative f'(x) = f(x)(1 - f(x)),\n",
    "\t    where f(x) is sigmoid function.\n",
    "\t    Inputs:\n",
    "\t    input: array\n",
    "\t    output: array, the results of the computation are to be stored here:\n",
    "\t    \t\tx(1 - x) for every element of the input matrix m1.\n",
    "\t*/\n",
    "\n",
    "\tfor (int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\t\t i < nThreads;\n",
    "\t\t i += blockDim.x * gridDim.x)\n",
    "\t  {\n",
    "\t\toutput[i] = input[i] * (1 - input[i]);\n",
    "\t  }\n",
    "}\n",
    "\n",
    "__device__ float* dSigmoid_d(float const *input, float *output, const int rows, const int columns){\n",
    "\tkSigmoid_d <<< rows, columns >>> (rows*columns, input, output);\n",
    "\tcudaDeviceSynchronize();\n",
    "\treturn output;\n",
    "}\n",
    "\n",
    "__global__ void kDot(const int nThreads, const float *m1, const float *m2, float *output, const int m1_rows , const int m1_columns, const int m2_columns ){\n",
    "\t/*  Computes the product of two matrices: m1 x m2.\n",
    "\t   \tInputs:\n",
    "\t    m1: array, left matrix of size m1_rows x m1_columns\n",
    "\t    m2: array, right matrix of size m1_columns x m2_columns (the number of rows in the right matrix\n",
    "\t    must be equal to the number of the columns in the left one)\n",
    "\t    output: array, the results of the computation are to be stored here:\n",
    "\t    \t\tm1 * m2, product of two arrays m1 and m2, a matrix of size m1_rows x m2_columns\n",
    "\t    m1_rows: int, number of rows in the left matrix m1\n",
    "\t    m1_columns: int, number of columns in the left matrix m1\n",
    "\t    m2_columns: int, number of columns in the right matrix m2\n",
    "\t*/\n",
    "\n",
    "\tfor (int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\t\t i < nThreads;\n",
    "\t\t i += blockDim.x * gridDim.x)\n",
    "\t{\n",
    "\t    int r = (int)i / m2_columns;\n",
    "\t    int c = i % m2_columns;\n",
    "\t    float t_output = 0.f;\n",
    "\n",
    "\t    for( int k = 0; k < m1_columns; ++k ) {\n",
    "\t        t_output += m1[ r * m1_columns + k ] * m2[ k * m2_columns + c ];\n",
    "\t    }\n",
    "\n",
    "\t    output[i] = t_output;\n",
    "\t}\n",
    "}\n",
    "\n",
    "__device__ float* dDot(const float *m1, const float *m2, float *output, const int m1_rows , const int m1_columns, const int m2_columns ){\n",
    "\n",
    "\tkDot <<< m1_rows, m2_columns >>> (m1_rows * m2_columns, m1, m2, output, m1_rows , m1_columns, m2_columns );\n",
    "\tcudaDeviceSynchronize();\n",
    "\treturn output;\n",
    "}\n",
    "\n",
    "__global__ void kDot_m1_m2T(const int nThreads, const float *m1, const float *m2, float *output, const int m1_columns, const int m2_rows ){\n",
    "\t/*  Updates the output matrix with the product of two matrices: m1 and m2 transposed.\n",
    "\t   \tInputs:\n",
    "\t    m1: array, left matrix of size m1_rows x m1_columns\n",
    "\t    m2: array, right matrix of size m2_rows x m1_columns (m2 transposed will be of size m1_columns x m2_rows)\n",
    "\t    output: array, the results of the computation are to be stored here:\n",
    "\t    \t\tm1 * m2, product of two arrays m1 and m2, a matrix of size m1_rows x m2_rows\n",
    "\t    m1_columns: int, number of columns in the left matrix m1\n",
    "\t    m2_rows: int, number of rows in the left matrix m2\n",
    "\t*/\n",
    "\n",
    "\tfor (int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\t\t i < nThreads;\n",
    "\t\t i += blockDim.x * gridDim.x)\n",
    "\t{\n",
    "\t\tint r = (int)i / m2_rows;\n",
    "\t\tint c = i % m2_rows;\n",
    "\t\tfloat t_output = 0.0;\n",
    "\t\tint id_T;\n",
    "\n",
    "\t\tfor( int k = 0; k < m1_columns; ++k ) {\n",
    "\t\t\tid_T = c * m1_columns + k;\n",
    "\t\t\tt_output += m1[ r * m1_columns + k ] * m2[ id_T ];\n",
    "\t\t}\n",
    "\n",
    "\t\toutput[i] = t_output;\n",
    "\t}\n",
    "}\n",
    "\n",
    "__device__ float* dDot_m1_m2T(const float *m1, const float *m2, float *output, const int m1_rows , const int m1_columns, const int m2_rows )\n",
    "{\n",
    "\tkDot_m1_m2T <<< m1_rows, m2_rows >>> ( m1_rows * m2_rows, m1, m2, output, m1_columns, m2_rows );\n",
    "\tcudaDeviceSynchronize();\n",
    "\treturn output;\n",
    "}\n",
    "\n",
    "__global__ void kDot_m1T_m2(const int nThreads, const float *m1, const float *m2, float *output, const int m1_rows,\n",
    "\t\t\t\t\t\t\tconst int m1_columns, const int m2_columns ){\n",
    "\t/*  Increments the output matrix with the product of two matrices: m1 transposed and m2.\n",
    "\t   \tInputs:\n",
    "\t    m1: array, left matrix of size m1_rows x m1_columns (m1 transposed will be of size m1_columns x m1_rows)\n",
    "\t    m2: array, right matrix of size m1_rows x m2_columns\n",
    "\t    output: array, the results of the computation are to be stored here:\n",
    "\t    \t\tm1 * m2, product of two arrays m1 and m2, a matrix of size m1_columns x m2_columns\n",
    "\t    m1_rows: int, number of rows in the left matrix m1\n",
    "\t    m1_columns: int, number of columns in the left matrix m1\n",
    "\t    m2_rows: int, number of rows in the left matrix m2\n",
    "\t*/\n",
    "\n",
    "\tfor (int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\t\t i < nThreads;\n",
    "\t\t i += blockDim.x * gridDim.x)\n",
    "\t{\n",
    "\t    int r = (int)i / m2_columns;\n",
    "\t    int c = i % m2_columns;\n",
    "\t    int id_T;\n",
    "\t    float t_output = 0.0;\n",
    "\n",
    "\t    for( int k = 0; k < m1_rows; ++k ) {\n",
    "\t    \tid_T = k * m1_columns + r;\n",
    "\t        t_output += m1[ id_T ] * m2[ k * m2_columns + c ];\n",
    "\t    }\n",
    "\n",
    "\t    output[i] += t_output;\n",
    "\t}\n",
    "}\n",
    "\n",
    "__device__ void dDot_m1T_m2(const float *m1, const float *m2, float *output, const int m1_height , const int m1_width, const int m2_width )\n",
    "{\n",
    "\tkDot_m1T_m2 <<< m1_width, m2_width >>> (m1_width * m2_width, m1, m2, output, m1_height, m1_width, m2_width );\n",
    "\tcudaDeviceSynchronize();\n",
    "}\n",
    "\n",
    "__device__ void kPrintMatrix (const float* M, int h, int w) {\n",
    "    /*  Prints out the input array as h x w matrix.\n",
    "     Inputs:\n",
    "     m: vector, matrix of size n_rows x n_columns\n",
    "     h: int, number of rows in the matrix M\n",
    "     w: int, number of columns in the matrix M\n",
    "     */\n",
    "\tfor (int i = 0; i < h; i++){\n",
    "\t\tfor (int j = 0; j < w; j++){\n",
    "\t\t\tprintf(\"%f  \", M[i*w+j]);\n",
    "\t\t}\n",
    "\t\tprintf(\"\\n\");\n",
    "\t}\n",
    "\tprintf(\"\\n\");\n",
    "}\n",
    "\n",
    "__global__ void kFit(\tconst float* X, const int X_w, const int X_h,\n",
    "\t\t\t\t\t\tconst float* y, const int y_w,\n",
    "\t\t\t\t\t\tfloat* l1, const int l1_w, float* l_1_d,\n",
    "\t\t\t\t\t\tfloat* pred, float* pred_d,\n",
    "\t\t\t\t\t\tfloat* W0,\n",
    "\t\t\t\t\t\tfloat* W1,\n",
    "\t\t\t\t\t\tfloat* buffer\n",
    "\t\t\t\t\t\t)\n",
    "{\n",
    "\tfor (unsigned i = 0; i < 50; ++i) {\n",
    "\n",
    "        dSigmoid(dDot(X, W0, l1, X_h, X_w, l1_w), l1, X_h, l1_w);\n",
    "        dSigmoid(dDot(l1, W1, pred, X_h, l1_w, y_w), pred, X_h, y_w);\n",
    "        dMartixByMatrixElementwise(dMartixSubstractMatrix(y, pred, pred_d, X_h, y_w), dSigmoid_d(pred, buffer, X_h, y_w), pred_d, X_h, y_w );\n",
    "        dMartixByMatrixElementwise(dDot_m1_m2T(pred_d, W1, l_1_d, X_h, y_w, l1_w), dSigmoid_d(l1, buffer, X_h, l1_w), l_1_d, X_h, l1_w);\n",
    "        dDot_m1T_m2( l1, pred_d, W1, X_h, l1_w, y_w );\n",
    "        dDot_m1T_m2( X, l_1_d, W0, X_h, X_w, l1_w );\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(void){\n",
    "\n",
    "\tconst int TRAINING_SIZE = 4;\n",
    "\tconst int TRAINING_DIM = 4;\n",
    "\tconst int L1_SIZE = 8;\n",
    "\n",
    "\t// X, the first 4 lines from Iris dataset\n",
    "\tfloat h_X[TRAINING_SIZE*TRAINING_DIM] = {\t5.1, 3.5, 1.4, 0.2,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t4.9, 3.0, 1.4, 0.2,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t6.2, 3.4, 5.4, 2.3,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t5.9, 3.0, 5.1, 1.8 };\n",
    "\n",
    "\tconst signed int X_size = sizeof(h_X);\n",
    "\n",
    "\tfloat *d_X;\n",
    "\tcudaMalloc(&d_X, X_size);\n",
    "\tcudaMemcpy(d_X, h_X, X_size, cudaMemcpyHostToDevice);\n",
    "\n",
    "\t//WEIGHTS_0\n",
    "\tconst long signed int W0_size = L1_SIZE*TRAINING_DIM*sizeof(float);\n",
    "\tfloat *h_W0 = (float*)malloc(W0_size);\n",
    "\tfor (int i = 0; i < L1_SIZE*TRAINING_DIM; i++){\n",
    "\t    h_W0[i] = 0.1 * (2.0*rand()/RAND_MAX-1.0);\n",
    "\t}\n",
    "\n",
    "\tfloat *d_W0;\n",
    "\tcudaMalloc(&d_W0, W0_size);\n",
    "\tcudaMemcpy(d_W0, h_W0, W0_size, cudaMemcpyHostToDevice);\n",
    "\n",
    "\t//LAYER_1, LAYER_1_DELTA AND BUFFER OF LAYER 1 SIZE\n",
    "\tconst long signed int L1_size = L1_SIZE*TRAINING_SIZE*sizeof(float);\n",
    "\n",
    "\tfloat* h_layer_1 = (float*)malloc(L1_size);\n",
    "\tfloat* h_layer_1_delta = (float*)malloc(L1_size);\n",
    "\tfloat* h_buffer = (float*)malloc(L1_size);\n",
    "\n",
    "\tfor (int i = 0; i < L1_SIZE*TRAINING_SIZE; i++){\n",
    "\t    h_layer_1[i] = 0.0;\n",
    "\t    h_buffer[i] = 0.0;\n",
    "\t    h_layer_1_delta[i] = 0.0;\n",
    "\t}\n",
    "\n",
    "\tfloat *d_layer_1;\n",
    "\tcudaMalloc(&d_layer_1, L1_size);\n",
    "\tcudaMemcpy(d_layer_1, h_layer_1, L1_size, cudaMemcpyHostToDevice);\n",
    "\n",
    "\tfloat *d_buffer;\n",
    "\tcudaMalloc(&d_buffer, L1_size);\n",
    "\tcudaMemcpy(d_buffer, h_buffer, L1_size, cudaMemcpyHostToDevice);\n",
    "\n",
    "\tfloat *d_layer_1_delta;\n",
    "\tcudaMalloc(&d_layer_1_delta, L1_size);\n",
    "\tcudaMemcpy(d_layer_1_delta, h_layer_1_delta, L1_size, cudaMemcpyHostToDevice);\n",
    "\n",
    "\t//WEIGHTS_1\n",
    "\tconst long signed int W1_size = L1_SIZE*sizeof(float);\n",
    "\tfloat *h_W1 = (float*)malloc(W1_size);\n",
    "\tfor (int i = 0; i < L1_SIZE; i++){\n",
    "\t    h_W1[i] = 0.1* (2.0*rand()/RAND_MAX-1.0);\n",
    "\t}\n",
    "\n",
    "\tfloat *d_W1;\n",
    "\tcudaMalloc(&d_W1, W1_size);\n",
    "\tcudaMemcpy(d_W1, h_W1, W1_size, cudaMemcpyHostToDevice);\n",
    "\n",
    "\t//Y\n",
    "\tfloat h_y[4] = {\t0,\n",
    "\t\t\t\t\t\t0,\n",
    "\t\t\t\t\t\t1,\n",
    "\t\t\t\t\t\t1 };\n",
    "\tconst signed int y_size = sizeof(h_y);\n",
    "\tfloat *d_y;\n",
    "\tcudaMalloc(&d_y, y_size);\n",
    "\tcudaMemcpy(d_y, h_y, y_size, cudaMemcpyHostToDevice);\n",
    "\n",
    "\t//PRED AND PRED_DELTA\n",
    "\tfloat* h_pred = (float*)malloc(y_size);\n",
    "\tfloat* h_pred_delta = (float*)malloc(y_size);\n",
    "\tfor (int i = 0; i < TRAINING_SIZE; i++){\n",
    "\t    h_pred[i] = 0.0;\n",
    "\t    h_pred_delta[i] = 0.0;\n",
    "\t}\n",
    "\n",
    "\tfloat *d_pred;\n",
    "\tcudaMalloc(&d_pred, y_size);\n",
    "\tcudaMemcpy(d_pred, h_pred, y_size, cudaMemcpyHostToDevice);\n",
    "\n",
    "\tfloat *d_pred_delta;\n",
    "\tcudaMalloc(&d_pred_delta, y_size);\n",
    "\tcudaMemcpy(d_pred_delta, h_pred_delta, y_size, cudaMemcpyHostToDevice);\n",
    "\n",
    "\tkFit <<< 1, 1 >>> (\td_X, TRAINING_DIM, TRAINING_SIZE,\n",
    "\t\t\t\t\t\td_y, 1,\n",
    "\t\t\t\t\t\td_layer_1, L1_SIZE, d_layer_1_delta,\n",
    "\t\t\t\t\t\td_pred,\n",
    "\t\t\t\t\t\td_pred_delta,\n",
    "\t\t\t\t\t\td_W0,\n",
    "\t\t\t\t\t\td_W1,\n",
    "\t\t\t\t\t\td_buffer);\n",
    "\n",
    "\tcudaMemcpy(h_pred, d_pred, y_size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "\tcudaFree(d_pred);\n",
    "\tcudaFree(d_X);\n",
    "\tcudaFree(d_y);\n",
    "\tcudaFree(d_layer_1_delta);\n",
    "\tcudaFree(d_pred_delta);\n",
    "\tcudaFree(d_W0);\n",
    "\tcudaFree(d_W1);\n",
    "\tcudaFree(d_buffer);\n",
    "\n",
    "\tfree(h_layer_1_delta);\n",
    "\tfree(h_pred_delta);\n",
    "\tfree(h_W0);\n",
    "\tfree(h_W1);\n",
    "\tfree(h_buffer);\n",
    "\n",
    "\tfor (int i = 0; i < TRAINING_SIZE; i++){\n",
    "\t\tprintf(\"Prediction[%i] : %f True Value[%i] : %f Error[%i] : %f\\n\", i, h_pred[i], i, h_y[i], i, h_pred[i] - h_y[i]);\n",
    "\t}\n",
    "\n",
    "\tfree(h_pred);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HErMbPCK4cMI",
    "outputId": "50867efa-927a-4dbd-dd94-264e1c538fb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true simple.cu -o simple -lcudadevrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WdYjfC6Ao_m",
    "outputId": "c7e82e1a-a95e-4eed-de55-8750f42896da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==1128== NVPROF is profiling process 1128, command: ./simple\n",
      "==1128== Warning: CDP tracing and profiling are not supported on devices with compute capability 7.0 and later.\n",
      "Prediction[0] : 0.060997 True Value[0] : 0.000000 Error[0] : 0.060997\n",
      "Prediction[1] : 0.076193 True Value[1] : 0.000000 Error[1] : 0.076193\n",
      "Prediction[2] : 0.927551 True Value[2] : 1.000000 Error[2] : -0.072449\n",
      "Prediction[3] : 0.918263 True Value[3] : 1.000000 Error[3] : -0.081737\n",
      "==1128== Profiling application: ./simple\n",
      "==1128== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   86.28%  13.280us         9  1.4750us  1.4080us  2.0160us  [CUDA memcpy HtoD]\n",
      "                   13.72%  2.1120us         1  2.1120us  2.1120us  2.1120us  [CUDA memcpy DtoH]\n",
      "      API calls:   85.08%  377.72ms         9  41.969ms  2.7700us  377.68ms  cudaMalloc\n",
      "                   14.71%  65.311ms        10  6.5311ms  5.1160us  65.208ms  cudaMemcpy\n",
      "                    0.13%  559.39us         1  559.39us  559.39us  559.39us  cuDeviceTotalMem\n",
      "                    0.05%  219.33us       101  2.1710us     164ns  91.373us  cuDeviceGetAttribute\n",
      "                    0.02%  66.601us         1  66.601us  66.601us  66.601us  cudaLaunchKernel\n",
      "                    0.01%  47.469us         8  5.9330us  2.5070us  16.794us  cudaFree\n",
      "                    0.01%  35.923us         1  35.923us  35.923us  35.923us  cuDeviceGetName\n",
      "                    0.00%  6.3860us         1  6.3860us  6.3860us  6.3860us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.3170us         3     772ns     306ns  1.4720us  cuDeviceGetCount\n",
      "                    0.00%  1.6100us         2     805ns     293ns  1.3170us  cuDeviceGet\n",
      "                    0.00%     366ns         1     366ns     366ns     366ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!nvprof ./simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grdXO3evBJfQ",
    "outputId": "cb1081c9-5522-4a03-85c8-c17d053d12c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction[0] : 0.060997 True Value[0] : 0.000000 Error[0] : 0.060997\n",
      "Prediction[1] : 0.076193 True Value[1] : 0.000000 Error[1] : 0.076193\n",
      "Prediction[2] : 0.927551 True Value[2] : 1.000000 Error[2] : -0.072449\n",
      "Prediction[3] : 0.918263 True Value[3] : 1.000000 Error[3] : -0.081737\n"
     ]
    }
   ],
   "source": [
    "!./simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9KLjEdM9-LL"
   },
   "outputs": [],
   "source": [
    "!nvcc 1.cu -o 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zch7gwOc-vLf",
    "outputId": "9eb93e4f-63a9-463c-910f-5d65d191f191"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "!./1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LmiMs2v4_Nxm",
    "outputId": "886d4bb7-602e-448d-d1cf-130b89ef6b8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n",
      "======== Warning: No profile data collected.\n"
     ]
    }
   ],
   "source": [
    "!nvprof ./1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zcrsJGN1_VDR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
